{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yenlung/Python-AI-Book/blob/main/%E9%99%84%E9%8C%84_%E7%B4%85%E6%A8%93%E5%A4%A2%E7%94%9F%E6%88%90%E5%99%A8%E7%9A%84%E5%8E%9F%E7%90%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VCsJrqL0Hf6B"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aH7puenFHf6F"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UXJFTVubHf6G"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, TimeDistributed, Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/yenlung/Python-AI-Book/main/dream.txt \\\n",
        "    -O /content/dream.txt"
      ],
      "metadata": {
        "id": "9OHDzK8uhtxg",
        "outputId": "4f512aeb-383e-424b-c1c4-6c7fa62c6688",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-19 22:48:36--  https://raw.githubusercontent.com/yenlung/Python-AI-Book/main/dream.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2656053 (2.5M) [text/plain]\n",
            "Saving to: ‘/content/dream.txt’\n",
            "\n",
            "/content/dream.txt  100%[===================>]   2.53M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-02-19 22:48:37 (32.0 MB/s) - ‘/content/dream.txt’ saved [2656053/2656053]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zk4u7hhpHf6H"
      },
      "outputs": [],
      "source": [
        "f = open('/content/dream.txt', 'r')\n",
        "lines = f.readlines()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dtonDVnaHf6I"
      },
      "outputs": [],
      "source": [
        "text_lines = [x.lstrip('\\u3000\\u3000') for x in lines]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MfNNhXknHf6I"
      },
      "outputs": [],
      "source": [
        "text = ''.join(text_lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "你當然可以欣賞一下裡面內容，不過太長了了這裡省略。"
      ],
      "metadata": {
        "id": "kg_X7RKQ3p_b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8-fUKNuQHf6J"
      },
      "outputs": [],
      "source": [
        "# text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKQ-ZNzdHf6L"
      },
      "source": [
        "### 訓練 tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ltK5zzP7Hf6P"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(char_level=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZUuWgGbeHf6R"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts([text])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEQwwABrHf6S"
      },
      "source": [
        "試用一下"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V1iYnlhZHf6U",
        "outputId": "8badecd2-36ae-4d1d-bd70-878f6485a36e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[250, 12, 6, 32, 37, 54, 13, 527, 370, 130, 440, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences([\"使人一見便知是奇物方妙。\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XXUUBS3Hf6V"
      },
      "source": [
        "變成文字。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_LY8s-AKHf6V",
        "outputId": "0aac0ee1-6169-472b-9f7e-60ed707c725b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'今天天氣很好'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "''.join(tokenizer.sequences_to_texts([[80, 113, 113, 139, 445, 39]])[0].split())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juEmBdSrHf6W"
      },
      "source": [
        "計算最大 id, 即不同的字的數目。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EMeZ-6LoHf6W"
      },
      "outputs": [],
      "source": [
        "max_id = len(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FyPaO2lIHf6X"
      },
      "outputs": [],
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([text]))-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qduJ8LbRHf6X"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_D4Gtks1Hf6Y"
      },
      "outputs": [],
      "source": [
        "n_steps = 100\n",
        "window_length = n_steps + 1\n",
        "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ysUgQNjnHf6Y",
        "outputId": "1c84770d-c8ba-4a13-98eb-823cf33e5ee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vEQXci56Hf6Z"
      },
      "outputs": [],
      "source": [
        "batch_size=32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:,:-1], windows[:,1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tEKW_FD3Hf6Z"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aHW_16jVHf6a"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PWMiysRHHf6a"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TSBJpUg1Hf6b"
      },
      "outputs": [],
      "source": [
        "model.add(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, input_shape=[None, max_id]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Hl7KfflQHf6b"
      },
      "outputs": [],
      "source": [
        "model.add(TimeDistributed(Dense(max_id, activation=\"softmax\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mt3608mNHf6b"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "yF8yE_qz35Hy",
        "outputId": "ec2b98ea-5571-47ad-fd0b-cf9750997519",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, None, 128)         2381312   \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, None, 4522)       583338    \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,964,650\n",
            "Trainable params: 2,964,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "開始訓練。"
      ],
      "metadata": {
        "id": "4bXqe8ro4A5L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIhcHFs0Hf6c",
        "outputId": "66808f6c-b4f1-474b-841c-27915bdc91cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "27545/27545 [==============================] - 3848s 140ms/step - loss: 4.2496\n",
            "Epoch 2/10\n",
            "27545/27545 [==============================] - 3846s 140ms/step - loss: 3.1537\n",
            "Epoch 3/10\n",
            "27545/27545 [==============================] - 3846s 140ms/step - loss: 2.9128\n",
            "Epoch 4/10\n",
            "27545/27545 [==============================] - 3842s 139ms/step - loss: 2.8136\n",
            "Epoch 5/10\n",
            "27545/27545 [==============================] - 3842s 139ms/step - loss: 2.7610\n",
            "Epoch 6/10\n",
            "27545/27545 [==============================] - 3843s 139ms/step - loss: 2.7279\n",
            "Epoch 7/10\n",
            "27545/27545 [==============================] - 3842s 139ms/step - loss: 2.7051\n",
            "Epoch 8/10\n",
            "27545/27545 [==============================] - 3841s 139ms/step - loss: 2.6880\n",
            "Epoch 9/10\n",
            "27545/27545 [==============================] - 3842s 139ms/step - loss: 2.6755\n",
            "Epoch 10/10\n",
            "27545/27545 [==============================] - 3841s 139ms/step - loss: 2.6661\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKa6qY0xHf6c"
      },
      "source": [
        "#### 把 model 存起來"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXUgcIoXHf6d",
        "outputId": "3c9d4307-ea53-44b2-85a0-dca33315488b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: dream_rnn/assets\n"
          ]
        }
      ],
      "source": [
        "model.save(\"dream_rnn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP67b3u0Hf6d"
      },
      "source": [
        "#### 把 tokenizer 存起來 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-JdRBLWHf6d"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8F5exZKHf6e"
      },
      "outputs": [],
      "source": [
        "f = open('dream_tokenizer.pkl', 'wb')\n",
        "pickle.dump(tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tf2py38]",
      "language": "python",
      "name": "conda-env-tf2py38-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "附錄_紅樓夢生成器的原理",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}